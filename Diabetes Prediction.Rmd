---
title: "Predicting Diabetes using SVM"
author: "Sajudra Gupta"
date: "`r Sys.Date()`"
output: html_document
---

Calling of required libraries
```{r}
library(dplyr)
library(tidyr)
library(caret)
library(rpart)
library(base)
```




# Part 1: Loading of data
```{r}
diabetes <- read.csv("diabetes.csv")
```

# Part 2: Exploratory data analysis
```{r}
#Checking the variables
head(diabetes)

#Summary of data provided
summary(diabetes)

#Count no. of NAs
colSums(is.na(diabetes))

table(diabetes$Outcome) #Checks the frequency of the given variable
hist(diabetes$Outcome) #Histogram for outcomes

```

From here, it is evident that the data is quite imbalanced. So, re-sampling techniques  are needed to ensure that it can prevent from making wrong predictions by prioritising the majority class. Before that, feature selection is required to prepare it for data split. Then, resampling can be done for the training data 

# Part 3: Data Preprocessing
```{r}
# Selection of necessary variables
diabetes_clean <- dplyr::select(diabetes, Glucose, BloodPressure, BMI, Insulin, Outcome)
head(diabetes_clean)
```

Now, the data can be split into train set and test set. Since SVM has a distance based approach, it is better to scale the data so that errors can be avoided. 

Here, some custom functions are created, to avoid repetitive tasks. 
```{r}
# Functions for scaling and splitting data
scale_dataset <- function(diabetes) #For data scaling
{
  X <- dplyr::select(diabetes, Glucose, BloodPressure, BMI, Insulin, Outcome)
  diabetes$Outcome = as.factor(diabetes$Outcome)
  X [,1:4] <- scale(X[,1:4])
  return(X)
}

split_data <- function(diabetes_clean) # For data splitting
{
  train_split = createDataPartition(diabetes_clean$Outcome, p = 0.8, list = FALSE)
  train_diabetes = diabetes_clean[train_split,]
  test_diabetes = diabetes_clean[-train_split,]
  return(list(train_diabetes,test_diabetes))
}
```

```{r}
#Scaling and splitting the dataset
diabetes_scale <- scale_dataset(diabetes)
set.seed(123) #For reproducibility
diabetes_test_train <- split_data(diabetes_scale)
train_diabetes = diabetes_test_train[[1]]
test_diabetes = diabetes_test_train [[2]]
```

Now the data has been successfully scaled and splitted into training set and test set. After that,resample is needed for the training data, in order to prevent wrong predictions. For this case, undersampling is used. 

```{r}
#Applying undersampling
train_diabetes$Outcome <- as.factor(train_diabetes$Outcome)
test_diabetes$Outcome <- as.factor(test_diabetes$Outcome)
train_diabetes_under <- downSample(train_diabetes[, -ncol(train_diabetes)], y = train_diabetes$Outcome, yname = "Outcome")
table(train_diabetes_under$Outcome) 
```

Now, it can be seen that the Outcome dataset is balanced, with both 0s and 1s having the same frequency. So now, it is ready for the model to be trained using linear support vector machine (SVM). We used a 5-fold cross validation, which was repeated 10 times for more accurate results.

# Training the model
```{r}
# Model training by implementing SVM
diabetes_model <- train(Outcome~., data = train_diabetes_under, method = "svmLinear", metric = "Accuracy", trControl = trainControl(method = "repeatedcv", number = 5, repeats = 10))
accuracy_train <- diabetes_model$results$Accuracy[1] #To extract accuracy
accuracy_train
pred_diabetes<-predict(diabetes_model, test_diabetes)
accuracy_test <-sum(pred_diabetes  == test_diabetes$Outcome) / nrow(test_diabetes)
accuracy_test
pres_diabetes<- posPredValue(pred_diabetes, test_diabetes$Outcome, positive = "1")
recall_diabetes <- sensitivity(pred_diabetes, test_diabetes$Outcome, positive = "1")
f1_diabetes<- (2 * recall_diabetes * pres_diabetes) / (recall_diabetes + pres_diabetes)


pres_diabetes
recall_diabetes
f1_diabetes
```

# Model results

|              Dataset             |              Accuracy              | 
|----------------------------------|------------------------------------|
| Training dataset                 |  `r round(accuracy_train *100, 2)` |
| Testing dataset                  |  `r round(accuracy_test *100, 2)`  | 

The table shows that the model has a good fit, it is safe to say that the model is now ready for testing. For testing, a  dataset with random data and check how the model predicts. 

First the model is saved in a file. 
```{r}
saveRDS(diabetes_model, "Diabetes Prediction.rds")
```

 

